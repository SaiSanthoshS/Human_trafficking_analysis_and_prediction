{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Human trafficking 15-20.csv')\n",
    "\n",
    "# Get the list of states from the first column\n",
    "states = df.iloc[:, 0].unique()\n",
    "\n",
    "# Create a dictionary to store the models and predictions for each state\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Loop over each state and train a separate LSTM model\n",
    "for state in states:\n",
    "    # Get the data for the current state\n",
    "    data = df[df.iloc[:, 0] == state].iloc[:, 1:].squeeze().values\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_data = data[:-2]\n",
    "    test_data = data[-2:]\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data = scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "    test_data = scaler.transform(test_data.reshape(-1, 1))\n",
    "\n",
    "    # Convert the data into sequences of length 3\n",
    "    train_sequences = []\n",
    "    train_labels = []\n",
    "    for i in range(3, len(train_data)):\n",
    "        train_sequences.append(train_data[i-3:i])\n",
    "        train_labels.append(train_data[i])\n",
    "    train_sequences = np.array(train_sequences)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(3, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_sequences, train_labels, epochs=100, verbose=0)\n",
    "\n",
    "    # Make predictions for the next 5 years\n",
    "    test_sequences = []\n",
    "    last_sequence = train_data[-3:]\n",
    "    for i in range(5):\n",
    "        next_sequence = model.predict(last_sequence.reshape(1, 3, 1))\n",
    "        test_sequences.append(next_sequence)\n",
    "        last_sequence = np.vstack([last_sequence[1:], next_sequence])\n",
    "    test_sequences = np.array(test_sequences)\n",
    "    test_sequences = scaler.inverse_transform(test_sequences.reshape(-1, 1)).squeeze()\n",
    "    predictions[state] = np.concatenate([data[:-2], test_sequences])\n",
    "\n",
    "    # Store the trained model\n",
    "    models[state] = model\n",
    "\n",
    "# Plot the predicted values for each state\n",
    "for state in states:\n",
    "    # Get the actual and predicted values for the current state\n",
    "    actual_values = df[df.iloc[:, 0] == state].iloc[:, 1:].squeeze().values\n",
    "    predicted_values = np.concatenate([actual_values[:-2], predictions[state], np.repeat(predictions[state][-1], 2)])\n",
    "\n",
    "    # Create a plot for the current state\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(actual_values, label='Actual Values')\n",
    "    plt.plot(predicted_values, label='Predicted Values')\n",
    "    plt.xticks(np.arange(len(actual_values)), np.arange(2015, 2023), rotation=45)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Cases')\n",
    "    plt.title(state)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the accuracy for each state\n",
    "accuracy = {}\n",
    "\n",
    "# Loop over each state\n",
    "for state in states:\n",
    "    # Get the actual and predicted values for the current state\n",
    "    actual_values = df[df.iloc[:, 0] == state].iloc[:, 1:].squeeze().values\n",
    "    predicted_values = np.concatenate([actual_values[:-2], predictions[state], np.repeat(predictions[state][-1], 2)])\n",
    "\n",
    "    # Calculate the mean absolute percentage error (MAPE) for the current state\n",
    "    mape = np.mean(np.abs((actual_values - predicted_values[:6]) / actual_values)) * 100\n",
    "\n",
    "    # Store the accuracy for the current state\n",
    "    accuracy[state] = 100 - mape\n",
    "\n",
    "# Print the accuracy for each state\n",
    "for state, acc in accuracy.items():\n",
    "    if acc != 'nan':\n",
    "        print(state, ':', acc, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the MAE for each state\n",
    "mae_dict = {}\n",
    "\n",
    "# Loop over each state\n",
    "for state in states:\n",
    "    # Get the actual and predicted values for the current state\n",
    "    actual_values = df[df.iloc[:, 0] == state].iloc[:, 1:].squeeze().values\n",
    "    predicted_values = np.concatenate([actual_values[:-2], predictions[state], np.repeat(predictions[state][-1], 2)])\n",
    "\n",
    "    # Calculate the MAE for the current state\n",
    "    mae = np.mean(np.abs(predicted_values[:6] - actual_values))\n",
    "    mae_dict[state] = mae\n",
    "\n",
    "# Print the MAE for each state\n",
    "for state, mae in mae_dict.items():\n",
    "    print(f\"MAE for {state}: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
